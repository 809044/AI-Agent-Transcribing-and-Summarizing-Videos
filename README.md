ğŸ¥âœ¨ AI Agent â€” Video Transcription & Summarization
Convert long videos into clean transcripts and concise AI summaries using Whisper + BART
<p align="center"> <img src="https://img.shields.io/badge/AI%20Powered-Yes-blueviolet?style=for-the-badge"/> <img src="https://img.shields.io/badge/Transcription-Whisper-green?style=for-the-badge"/> <img src="https://img.shields.io/badge/Summarization-BART-orange?style=for-the-badge"/> <img src="https://img.shields.io/badge/UI-Streamlit-red?style=for-the-badge"/> <img src="https://img.shields.io/badge/Category-ML%20Application-yellow?style=for-the-badge"/> </p>
ğŸŒŸ Overview

This project is a powerful AI-driven video processing tool that automatically converts video files into:

ğŸ“ Complete text transcripts

ğŸ§  Well-structured AI summaries

ğŸŒ Using a simple, modern Streamlit interface

Whether you're a student, content creator, researcher, or professional, this tool saves hours by extracting insights from long videos instantly.

ğŸ“¸ Application Screenshot
<p align="center"> <img src="Screenshot 2025-11-14 210816.png" width="85%" alt="App Screenshot"/> </p>
ğŸš€ Features
1ï¸âƒ£ ğŸ¬ Video-to-Audio Extraction

Uses FFmpeg to extract clean audio from MP4, MOV, AVI, MKV

Ensures high-quality input for transcription

2ï¸âƒ£ ğŸ—£ï¸ Whisper Speech-to-Text

Powered by OpenAI Whisper

Handles multiple accents, background noise, and long videos

Produces accurate, punctuation-ready transcripts

3ï¸âƒ£ âœ‚ï¸ Smart Text Chunking

Automatically splits long transcripts

Avoids token overflow for summarization models

Maintains flow and context across chunks

4ï¸âƒ£ ğŸ§  BART-Based Text Summarization

Uses Hugging Face BART

Generates clean, concise, human-like summaries

Ideal for note-taking, research, and quick understanding

5ï¸âƒ£ ğŸŒ Modern Streamlit UI

Drag-and-drop video upload

Real-time processing indicators

Dark mode friendly interface

Zero technical knowledge required

ğŸ”„ Processing Pipeline
ğŸ¥ Video Input
      â†“
ğŸ§ Audio Extraction (FFmpeg)
      â†“
ğŸ—£ï¸ Speech-to-Text (Whisper)
      â†“
âœ‚ï¸ Text Chunking
      â†“
ğŸ§  BART AI Summarization
      â†“
ğŸ“ Final Output (Transcript + Summary)

ğŸ“ Project Structure
AI-Agent-Transcribing-and-Summarizing-Videos/
â”‚
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ main.py                    # Main pipeline controller
â”œâ”€â”€ transcriber.py             # Whisper + audio extraction
â”œâ”€â”€ summarizer.py              # BART summarization logic
â”œâ”€â”€ utils.py                   # Chunking and text helpers
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ Screenshot 2025-11-14.png  # Screenshot used in README
â””â”€â”€ notes.txt

âš™ï¸ Technology Stack
ğŸ¤– Machine Learning Models

Whisper (Speech-to-Text)

BART Transformer (Summarization)

PyTorch backend

ğŸ§© Tools & Frameworks

Streamlit

FFmpeg / ffmpeg-python

Hugging Face Transformers

ğŸ–¥ï¸ Programming

Python 3.10+

ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/your-username/AI-Agent-Transcribing-and-Summarizing-Videos.git
cd AI-Agent-Transcribing-and-Summarizing-Videos

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Install FFmpeg

Windows: download from ffmpeg.org

macOS: brew install ffmpeg

Linux: sudo apt install ffmpeg

â–¶ï¸ Run the Application
streamlit run app.py


Your browser will open with the interface where you can upload videos for transcription and summarization.

ğŸ“ Example Summary Output

â€œA Data Scientist is a professional who uses data to solve business problems.
They work with large datasets, apply statistical models, machine learning,
and computational methods to derive insights and make data-driven decisions.â€

ğŸ›£ï¸ Roadmap

 Multi-language transcription

 Multi-model summarization support

 Export transcript + summary to PDF

 Time-stamped transcripts

 Cloud deployment

 UI enhancements and animations

ğŸ¤ Contributing

Pull requests are welcome!
If you have suggestions or want to add new features, feel free to open an issue.

ğŸ“ License

This project is open-source and available under the MIT License.
